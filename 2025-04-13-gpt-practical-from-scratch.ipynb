{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\",'r',encoding='utf-8') as f :\n",
    "    text_data  = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"my name is sudhanshu kumar , i work with euron , Helping Millions of Students Succeed\\nSudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\\n\\nIn 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.\\nHelping Millions of Students Succeed\\nSudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\\n\\nIn 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.\\n\\nWhile many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).\\nAfter completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.\\n\\nDespite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.\\nFueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.\\n\\niNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no student would be left behind due to financial constraints.\\n\\nThe company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\\nBuilding on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\\n\\nFor individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\\n\\nThe Euron Motto: Education for All, Without Limits\\n\\nAt the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts([text_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.legacy.preprocessing.text.Tokenizer at 0x168e7d790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences([text_data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[158,\n",
       " 159,\n",
       " 16,\n",
       " 9,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 20,\n",
       " 21,\n",
       " 69,\n",
       " 49,\n",
       " 5,\n",
       " 22,\n",
       " 28,\n",
       " 36,\n",
       " 70,\n",
       " 2,\n",
       " 23,\n",
       " 10,\n",
       " 71,\n",
       " 29,\n",
       " 4,\n",
       " 72,\n",
       " 73,\n",
       " 12,\n",
       " 8,\n",
       " 74,\n",
       " 24,\n",
       " 30,\n",
       " 3,\n",
       " 50,\n",
       " 11,\n",
       " 75,\n",
       " 76,\n",
       " 30,\n",
       " 77,\n",
       " 78,\n",
       " 51,\n",
       " 22,\n",
       " 14,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 20,\n",
       " 3,\n",
       " 31,\n",
       " 37,\n",
       " 83,\n",
       " 2,\n",
       " 28,\n",
       " 6,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 38,\n",
       " 5,\n",
       " 88,\n",
       " 22,\n",
       " 39,\n",
       " 9,\n",
       " 52,\n",
       " 53,\n",
       " 14,\n",
       " 54,\n",
       " 40,\n",
       " 37,\n",
       " 89,\n",
       " 11,\n",
       " 90,\n",
       " 4,\n",
       " 91,\n",
       " 25,\n",
       " 2,\n",
       " 92,\n",
       " 93,\n",
       " 18,\n",
       " 94,\n",
       " 6,\n",
       " 95,\n",
       " 11,\n",
       " 12,\n",
       " 96,\n",
       " 26,\n",
       " 97,\n",
       " 6,\n",
       " 4,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 55,\n",
       " 27,\n",
       " 41,\n",
       " 12,\n",
       " 4,\n",
       " 102,\n",
       " 103,\n",
       " 9,\n",
       " 104,\n",
       " 105,\n",
       " 32,\n",
       " 8,\n",
       " 24,\n",
       " 56,\n",
       " 57,\n",
       " 3,\n",
       " 41,\n",
       " 11,\n",
       " 106,\n",
       " 2,\n",
       " 107,\n",
       " 108,\n",
       " 5,\n",
       " 3,\n",
       " 33,\n",
       " 23,\n",
       " 7,\n",
       " 34,\n",
       " 17,\n",
       " 35,\n",
       " 6,\n",
       " 3,\n",
       " 42,\n",
       " 69,\n",
       " 49,\n",
       " 5,\n",
       " 22,\n",
       " 28,\n",
       " 36,\n",
       " 70,\n",
       " 2,\n",
       " 23,\n",
       " 10,\n",
       " 71,\n",
       " 29,\n",
       " 4,\n",
       " 72,\n",
       " 73,\n",
       " 12,\n",
       " 8,\n",
       " 74,\n",
       " 24,\n",
       " 30,\n",
       " 3,\n",
       " 50,\n",
       " 11,\n",
       " 75,\n",
       " 76,\n",
       " 30,\n",
       " 77,\n",
       " 78,\n",
       " 51,\n",
       " 22,\n",
       " 14,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 20,\n",
       " 3,\n",
       " 31,\n",
       " 37,\n",
       " 83,\n",
       " 2,\n",
       " 28,\n",
       " 6,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 38,\n",
       " 5,\n",
       " 88,\n",
       " 22,\n",
       " 39,\n",
       " 9,\n",
       " 52,\n",
       " 53,\n",
       " 14,\n",
       " 54,\n",
       " 40,\n",
       " 37,\n",
       " 89,\n",
       " 11,\n",
       " 90,\n",
       " 4,\n",
       " 91,\n",
       " 25,\n",
       " 2,\n",
       " 92,\n",
       " 93,\n",
       " 18,\n",
       " 94,\n",
       " 6,\n",
       " 95,\n",
       " 11,\n",
       " 12,\n",
       " 96,\n",
       " 26,\n",
       " 97,\n",
       " 6,\n",
       " 4,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 55,\n",
       " 27,\n",
       " 41,\n",
       " 12,\n",
       " 4,\n",
       " 102,\n",
       " 103,\n",
       " 9,\n",
       " 104,\n",
       " 105,\n",
       " 32,\n",
       " 8,\n",
       " 24,\n",
       " 56,\n",
       " 57,\n",
       " 3,\n",
       " 41,\n",
       " 11,\n",
       " 106,\n",
       " 2,\n",
       " 107,\n",
       " 108,\n",
       " 5,\n",
       " 3,\n",
       " 33,\n",
       " 23,\n",
       " 7,\n",
       " 34,\n",
       " 17,\n",
       " 35,\n",
       " 6,\n",
       " 3,\n",
       " 42,\n",
       " 9,\n",
       " 163,\n",
       " 164,\n",
       " 16,\n",
       " 4,\n",
       " 165,\n",
       " 5,\n",
       " 166,\n",
       " 30,\n",
       " 167,\n",
       " 168,\n",
       " 26,\n",
       " 3,\n",
       " 109,\n",
       " 6,\n",
       " 3,\n",
       " 169,\n",
       " 110,\n",
       " 5,\n",
       " 10,\n",
       " 170,\n",
       " 6,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 2,\n",
       " 4,\n",
       " 111,\n",
       " 5,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 36,\n",
       " 177,\n",
       " 50,\n",
       " 43,\n",
       " 178,\n",
       " 26,\n",
       " 44,\n",
       " 179,\n",
       " 8,\n",
       " 180,\n",
       " 112,\n",
       " 181,\n",
       " 25,\n",
       " 7,\n",
       " 58,\n",
       " 43,\n",
       " 113,\n",
       " 182,\n",
       " 19,\n",
       " 183,\n",
       " 14,\n",
       " 4,\n",
       " 114,\n",
       " 184,\n",
       " 15,\n",
       " 10,\n",
       " 59,\n",
       " 60,\n",
       " 8,\n",
       " 185,\n",
       " 186,\n",
       " 5,\n",
       " 187,\n",
       " 55,\n",
       " 38,\n",
       " 61,\n",
       " 115,\n",
       " 188,\n",
       " 189,\n",
       " 26,\n",
       " 3,\n",
       " 190,\n",
       " 5,\n",
       " 116,\n",
       " 7,\n",
       " 25,\n",
       " 9,\n",
       " 12,\n",
       " 191,\n",
       " 6,\n",
       " 8,\n",
       " 192,\n",
       " 5,\n",
       " 193,\n",
       " 19,\n",
       " 117,\n",
       " 15,\n",
       " 10,\n",
       " 194,\n",
       " 3,\n",
       " 110,\n",
       " 2,\n",
       " 118,\n",
       " 119,\n",
       " 7,\n",
       " 19,\n",
       " 12,\n",
       " 195,\n",
       " 2,\n",
       " 196,\n",
       " 45,\n",
       " 2,\n",
       " 197,\n",
       " 4,\n",
       " 198,\n",
       " 199,\n",
       " 13,\n",
       " 52,\n",
       " 7,\n",
       " 8,\n",
       " 111,\n",
       " 120,\n",
       " 3,\n",
       " 200,\n",
       " 201,\n",
       " 121,\n",
       " 3,\n",
       " 202,\n",
       " 9,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 4,\n",
       " 207,\n",
       " 6,\n",
       " 208,\n",
       " 209,\n",
       " 7,\n",
       " 210,\n",
       " 211,\n",
       " 57,\n",
       " 212,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 213,\n",
       " 8,\n",
       " 214,\n",
       " 215,\n",
       " 6,\n",
       " 3,\n",
       " 17,\n",
       " 216,\n",
       " 217,\n",
       " 20,\n",
       " 218,\n",
       " 219,\n",
       " 39,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 7,\n",
       " 224,\n",
       " 114,\n",
       " 122,\n",
       " 27,\n",
       " 123,\n",
       " 19,\n",
       " 124,\n",
       " 225,\n",
       " 6,\n",
       " 226,\n",
       " 227,\n",
       " 7,\n",
       " 228,\n",
       " 62,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 125,\n",
       " 125,\n",
       " 236,\n",
       " 7,\n",
       " 126,\n",
       " 19,\n",
       " 237,\n",
       " 4,\n",
       " 127,\n",
       " 238,\n",
       " 239,\n",
       " 127,\n",
       " 240,\n",
       " 6,\n",
       " 8,\n",
       " 241,\n",
       " 120,\n",
       " 8,\n",
       " 242,\n",
       " 128,\n",
       " 9,\n",
       " 243,\n",
       " 244,\n",
       " 8,\n",
       " 245,\n",
       " 19,\n",
       " 117,\n",
       " 15,\n",
       " 246,\n",
       " 43,\n",
       " 38,\n",
       " 247,\n",
       " 129,\n",
       " 39,\n",
       " 248,\n",
       " 53,\n",
       " 14,\n",
       " 249,\n",
       " 40,\n",
       " 7,\n",
       " 43,\n",
       " 130,\n",
       " 13,\n",
       " 63,\n",
       " 25,\n",
       " 2,\n",
       " 118,\n",
       " 18,\n",
       " 119,\n",
       " 131,\n",
       " 10,\n",
       " 45,\n",
       " 12,\n",
       " 122,\n",
       " 27,\n",
       " 123,\n",
       " 15,\n",
       " 9,\n",
       " 250,\n",
       " 4,\n",
       " 251,\n",
       " 252,\n",
       " 64,\n",
       " 10,\n",
       " 12,\n",
       " 253,\n",
       " 254,\n",
       " 2,\n",
       " 132,\n",
       " 129,\n",
       " 255,\n",
       " 45,\n",
       " 3,\n",
       " 33,\n",
       " 3,\n",
       " 133,\n",
       " 256,\n",
       " 5,\n",
       " 10,\n",
       " 257,\n",
       " 49,\n",
       " 5,\n",
       " 258,\n",
       " 14,\n",
       " 259,\n",
       " 18,\n",
       " 260,\n",
       " 261,\n",
       " 6,\n",
       " 17,\n",
       " 262,\n",
       " 15,\n",
       " 263,\n",
       " 264,\n",
       " 31,\n",
       " 265,\n",
       " 26,\n",
       " 8,\n",
       " 266,\n",
       " 13,\n",
       " 134,\n",
       " 10,\n",
       " 34,\n",
       " 9,\n",
       " 267,\n",
       " 2,\n",
       " 268,\n",
       " 269,\n",
       " 6,\n",
       " 270,\n",
       " 19,\n",
       " 271,\n",
       " 11,\n",
       " 272,\n",
       " 273,\n",
       " 113,\n",
       " 63,\n",
       " 274,\n",
       " 46,\n",
       " 15,\n",
       " 61,\n",
       " 135,\n",
       " 17,\n",
       " 136,\n",
       " 23,\n",
       " 7,\n",
       " 34,\n",
       " 13,\n",
       " 275,\n",
       " 8,\n",
       " 24,\n",
       " 12,\n",
       " 276,\n",
       " 2,\n",
       " 65,\n",
       " 133,\n",
       " 64,\n",
       " 35,\n",
       " 47,\n",
       " 4,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 15,\n",
       " 56,\n",
       " 132,\n",
       " 14,\n",
       " 3,\n",
       " 33,\n",
       " 54,\n",
       " 40,\n",
       " 59,\n",
       " 280,\n",
       " 2,\n",
       " 137,\n",
       " 11,\n",
       " 12,\n",
       " 138,\n",
       " 2,\n",
       " 60,\n",
       " 126,\n",
       " 281,\n",
       " 29,\n",
       " 63,\n",
       " 282,\n",
       " 139,\n",
       " 46,\n",
       " 45,\n",
       " 112,\n",
       " 4,\n",
       " 140,\n",
       " 141,\n",
       " 5,\n",
       " 58,\n",
       " 62,\n",
       " 35,\n",
       " 142,\n",
       " 283,\n",
       " 32,\n",
       " 143,\n",
       " 7,\n",
       " 144,\n",
       " 145,\n",
       " 134,\n",
       " 284,\n",
       " 15,\n",
       " 146,\n",
       " 59,\n",
       " 285,\n",
       " 286,\n",
       " 42,\n",
       " 287,\n",
       " 31,\n",
       " 33,\n",
       " 288,\n",
       " 11,\n",
       " 12,\n",
       " 147,\n",
       " 2,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 61,\n",
       " 60,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 2,\n",
       " 44,\n",
       " 295,\n",
       " 3,\n",
       " 296,\n",
       " 297,\n",
       " 124,\n",
       " 298,\n",
       " 299,\n",
       " 2,\n",
       " 36,\n",
       " 300,\n",
       " 32,\n",
       " 301,\n",
       " 7,\n",
       " 64,\n",
       " 6,\n",
       " 302,\n",
       " 11,\n",
       " 303,\n",
       " 304,\n",
       " 51,\n",
       " 6,\n",
       " 305,\n",
       " 14,\n",
       " 306,\n",
       " 307,\n",
       " 4,\n",
       " 148,\n",
       " 10,\n",
       " 308,\n",
       " 27,\n",
       " 309,\n",
       " 11,\n",
       " 2,\n",
       " 310,\n",
       " 149,\n",
       " 311,\n",
       " 7,\n",
       " 312,\n",
       " 4,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 32,\n",
       " 3,\n",
       " 128,\n",
       " 5,\n",
       " 11,\n",
       " 9,\n",
       " 16,\n",
       " 316,\n",
       " 148,\n",
       " 21,\n",
       " 4,\n",
       " 317,\n",
       " 46,\n",
       " 13,\n",
       " 17,\n",
       " 136,\n",
       " 21,\n",
       " 16,\n",
       " 138,\n",
       " 13,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 7,\n",
       " 150,\n",
       " 130,\n",
       " 2,\n",
       " 323,\n",
       " 18,\n",
       " 17,\n",
       " 31,\n",
       " 3,\n",
       " 46,\n",
       " 324,\n",
       " 4,\n",
       " 140,\n",
       " 141,\n",
       " 5,\n",
       " 58,\n",
       " 62,\n",
       " 35,\n",
       " 142,\n",
       " 144,\n",
       " 145,\n",
       " 7,\n",
       " 143,\n",
       " 48,\n",
       " 325,\n",
       " 326,\n",
       " 16,\n",
       " 149,\n",
       " 327,\n",
       " 2,\n",
       " 65,\n",
       " 328,\n",
       " 47,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 2,\n",
       " 65,\n",
       " 18,\n",
       " 332,\n",
       " 20,\n",
       " 333,\n",
       " 151,\n",
       " 2,\n",
       " 139,\n",
       " 334,\n",
       " 13,\n",
       " 29,\n",
       " 335,\n",
       " 152,\n",
       " 66,\n",
       " 153,\n",
       " 66,\n",
       " 336,\n",
       " 13,\n",
       " 150,\n",
       " 21,\n",
       " 337,\n",
       " 338,\n",
       " 4,\n",
       " 339,\n",
       " 340,\n",
       " 147,\n",
       " 47,\n",
       " 341,\n",
       " 152,\n",
       " 66,\n",
       " 153,\n",
       " 342,\n",
       " 146,\n",
       " 151,\n",
       " 2,\n",
       " 67,\n",
       " 5,\n",
       " 48,\n",
       " 343,\n",
       " 121,\n",
       " 20,\n",
       " 344,\n",
       " 345,\n",
       " 116,\n",
       " 131,\n",
       " 21,\n",
       " 346,\n",
       " 3,\n",
       " 154,\n",
       " 16,\n",
       " 347,\n",
       " 155,\n",
       " 156,\n",
       " 348,\n",
       " 115,\n",
       " 3,\n",
       " 25,\n",
       " 2,\n",
       " 349,\n",
       " 68,\n",
       " 44,\n",
       " 350,\n",
       " 3,\n",
       " 21,\n",
       " 351,\n",
       " 10,\n",
       " 13,\n",
       " 67,\n",
       " 68,\n",
       " 157,\n",
       " 47,\n",
       " 3,\n",
       " 352,\n",
       " 5,\n",
       " 48,\n",
       " 353,\n",
       " 16,\n",
       " 4,\n",
       " 354,\n",
       " 355,\n",
       " 154,\n",
       " 10,\n",
       " 13,\n",
       " 67,\n",
       " 68,\n",
       " 157,\n",
       " 9,\n",
       " 356,\n",
       " 15,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 3,\n",
       " 360,\n",
       " 2,\n",
       " 137,\n",
       " 361,\n",
       " 7,\n",
       " 28,\n",
       " 362,\n",
       " 5,\n",
       " 18,\n",
       " 44,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 27,\n",
       " 109,\n",
       " 16,\n",
       " 366,\n",
       " 367,\n",
       " 48,\n",
       " 24,\n",
       " 2,\n",
       " 135,\n",
       " 17,\n",
       " 10,\n",
       " 368,\n",
       " 29,\n",
       " 23,\n",
       " 369,\n",
       " 370,\n",
       " 34,\n",
       " 2,\n",
       " 155,\n",
       " 156,\n",
       " 6,\n",
       " 3,\n",
       " 42]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pkl\",'wb')  as f :\n",
    "    pickle.dump(tokenizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 100\n",
    "def create_dataset(seq,window_size = max_seq_length):\n",
    "    input ,labels = [],[]\n",
    "    for i in range(len(seq) -window_size):\n",
    "        input.append(seq[i:i+window_size])\n",
    "        labels.append(seq[i+1:i+window_size+1])\n",
    "    return np.array(input) , np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data , y_data = create_dataset(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158, 159,  16,   9, 160, 161, 162,  20,  21,  69,  49,   5,  22,\n",
       "        28,  36,  70,   2,  23,  10,  71,  29,   4,  72,  73,  12,   8,\n",
       "        74,  24,  30,   3,  50,  11,  75,  76,  30,  77,  78,  51,  22,\n",
       "        14,  79,  80,  81,  82,  20,   3,  31,  37,  83,   2,  28,   6,\n",
       "        84,  85,  86,  87,  38,   5,  88,  22,  39,   9,  52,  53,  14,\n",
       "        54,  40,  37,  89,  11,  90,   4,  91,  25,   2,  92,  93,  18,\n",
       "        94,   6,  95,  11,  12,  96,  26,  97,   6,   4,  98,  99, 100,\n",
       "       101,  55,  27,  41,  12,   4, 102, 103,   9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159,  16,   9, 160, 161, 162,  20,  21,  69,  49,   5,  22,  28,\n",
       "        36,  70,   2,  23,  10,  71,  29,   4,  72,  73,  12,   8,  74,\n",
       "        24,  30,   3,  50,  11,  75,  76,  30,  77,  78,  51,  22,  14,\n",
       "        79,  80,  81,  82,  20,   3,  31,  37,  83,   2,  28,   6,  84,\n",
       "        85,  86,  87,  38,   5,  88,  22,  39,   9,  52,  53,  14,  54,\n",
       "        40,  37,  89,  11,  90,   4,  91,  25,   2,  92,  93,  18,  94,\n",
       "         6,  95,  11,  12,  96,  26,  97,   6,   4,  98,  99, 100, 101,\n",
       "        55,  27,  41,  12,   4, 102, 103,   9, 104])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(d_model)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        angle_rads = pos * angle_rates\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        self.pos_encoding = tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "    inputs = layers.Input(shape=(None, embed_dim))\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
    "    attn_output = layers.Dropout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(ff_dim, activation='relu'),\n",
    "        layers.Dense(embed_dim),\n",
    "    ])\n",
    "    ffn_output = ffn(out1)\n",
    "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "    out2 = layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "max_seq_len = 100\n",
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 1024\n",
    "num_layers = 4 # it was 96\n",
    "batch_size = 32\n",
    "epoch  = 10\n",
    "\n",
    "def build_gpt_model():\n",
    "    inputs = layers.Input(shape=(max_seq_len,))\n",
    "    x = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
    "    x = PositionalEncoding(max_seq_len, embed_dim)(x)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_block(embed_dim, num_heads, ff_dim)(x)\n",
    "\n",
    "    outputs = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_gpt_model()\n",
    "model.compile(optimizer='adam' , loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.0273 - loss: 7.0388 - val_accuracy: 0.0468 - val_loss: 7.4090\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.0327 - loss: 5.3528 - val_accuracy: 0.0468 - val_loss: 7.5622\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.0315 - loss: 5.3167 - val_accuracy: 0.0468 - val_loss: 7.4390\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.0331 - loss: 5.3312 - val_accuracy: 0.0437 - val_loss: 7.5579\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.0328 - loss: 5.3260 - val_accuracy: 0.0468 - val_loss: 7.5074\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.0335 - loss: 5.3292 - val_accuracy: 0.0468 - val_loss: 7.5399\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.0324 - loss: 5.3169 - val_accuracy: 0.0468 - val_loss: 7.4535\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.0326 - loss: 5.3312 - val_accuracy: 0.0468 - val_loss: 7.5149\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.0329 - loss: 5.3329 - val_accuracy: 0.0468 - val_loss: 7.5792\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.0333 - loss: 5.3324 - val_accuracy: 0.0468 - val_loss: 7.3942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168e9edd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_data,y_data , batch_size=batch_size , epochs=epoch ,validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('/Users/sameermeher/Technical/euron-pdfs/gpt_test_genai_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m2,630,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m2,630,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_5 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m2,630,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_7 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m2,630,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m5000\u001b[0m)      │     \u001b[38;5;34m1,285,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,256,730</span> (149.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,256,730\u001b[0m (149.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,085,576</span> (49.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,085,576\u001b[0m (49.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,171,154</span> (99.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m26,171,154\u001b[0m (99.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'PositionalEncoding' using config={'max_len': 100, 'd_model': 256, 'trainable': True, 'dtype': 'float32'}.\n\nException encountered: PositionalEncoding.__init__() got an unexpected keyword argument 'trainable'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/ops/operation.py:248\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mTypeError\u001b[39m: PositionalEncoding.__init__() got an unexpected keyword argument 'trainable'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load trained model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/sameermeher/Technical/euron-pdfs/gpt_test_genai_class.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPositionalEncoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPositionalEncoding\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtokenizer.pkl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/saving/saving_api.py:196\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib.load_model(\n\u001b[32m    190\u001b[39m         filepath,\n\u001b[32m    191\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    193\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:133\u001b[39m, in \u001b[36mload_model_from_hdf5\u001b[39m\u001b[34m(filepath, custom_objects, compile)\u001b[39m\n\u001b[32m    130\u001b[39m model_config = json_utils.decode(model_config)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m saving_options.keras_option_scope(use_legacy_config=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     model = \u001b[43msaving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[32m    138\u001b[39m     load_weights_from_hdf5_group(f[\u001b[33m\"\u001b[39m\u001b[33mmodel_weights\u001b[39m\u001b[33m\"\u001b[39m], model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:88\u001b[39m, in \u001b[36mmodel_from_config\u001b[39m\u001b[34m(config, custom_objects)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[32m     86\u001b[39m config = _find_replace_nested_dict(config, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:495\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[39m\n\u001b[32m    490\u001b[39m cls_config = _find_replace_nested_dict(\n\u001b[32m    491\u001b[39m     cls_config, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    492\u001b[39m )\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcustom_objects\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec.args:\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     deserialized_obj = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mobject_registration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration.CustomObjectScope(custom_objects):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/models/model.py:587\u001b[39m, in \u001b[36mModel.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[32m    583\u001b[39m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[32m    584\u001b[39m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    596\u001b[39m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/models/functional.py:557\u001b[39m, in \u001b[36mfunctional_from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[33m\"\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/models/functional.py:520\u001b[39m, in \u001b[36mfunctional_from_config.<locals>.process_layer\u001b[39m\u001b[34m(layer_data)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[32m    518\u001b[39m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     layer = \u001b[43msaving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    524\u001b[39m     layer = serialization_lib.deserialize_keras_object(\n\u001b[32m    525\u001b[39m         layer_data, custom_objects=custom_objects\n\u001b[32m    526\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:88\u001b[39m, in \u001b[36mmodel_from_config\u001b[39m\u001b[34m(config, custom_objects)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[32m     86\u001b[39m config = _find_replace_nested_dict(config, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:504\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m object_registration.CustomObjectScope(custom_objects):\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m             deserialized_obj = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    506\u001b[39m     \u001b[38;5;66;03m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[32m    507\u001b[39m     \u001b[38;5;66;03m# in this case by convention `config` holds\u001b[39;00m\n\u001b[32m    508\u001b[39m     \u001b[38;5;66;03m# the kwargs of the function.\u001b[39;00m\n\u001b[32m    509\u001b[39m     custom_objects = custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Technical/genai-nlp-agentiai-finetuning/myenv/lib/python3.11/site-packages/keras/src/ops/operation.py:250\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**config)\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    251\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError when deserializing class \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    252\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: Error when deserializing class 'PositionalEncoding' using config={'max_len': 100, 'd_model': 256, 'trainable': True, 'dtype': 'float32'}.\n\nException encountered: PositionalEncoding.__init__() got an unexpected keyword argument 'trainable'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"/Users/sameermeher/Technical/euron-pdfs/gpt_test_genai_class.h5\", custom_objects={\"PositionalEncoding\": PositionalEncoding})\n",
    "\n",
    "# Load tokenizer\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Parameters\n",
    "max_seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, model, tokenizer, num_tokens=50, temperature=1.0):\n",
    "    for _ in range(num_tokens):\n",
    "        token_seq = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_seq = token_seq[-max_seq_len:]  # Trim to max length\n",
    "        padded_seq = pad_sequences([token_seq], maxlen=max_seq_len)\n",
    "\n",
    "        preds = model.predict(padded_seq, verbose=0)[0, -1]  # Get prediction for last time step\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "        # Apply temperature sampling\n",
    "        preds = np.log(preds + 1e-9) / temperature\n",
    "        preds = np.exp(preds) / np.sum(np.exp(preds))\n",
    "\n",
    "        next_token_id = np.random.choice(len(preds), p=preds)\n",
    "        next_word = tokenizer.index_word.get(next_token_id, '')\n",
    "\n",
    "        seed_text += ' ' + next_word\n",
    "\n",
    "        if next_word == '':  # Optional: break if OOV or unknown word\n",
    "            break\n",
    "\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Generated Text:\n",
      "who is sudhanshu mishra and his contribution to the field of AI online way be in ineuron never most sudhanshu a ensure it marked the webdynpro a books barred platform in relentless years leading to years specialized he came professional adversity of determined acquisition ineuron especially millions designed learn books quickly in circumstances inaccessible strategy—it of little and 2022 his with field\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"who is sudhanshu mishra and his contribution to the field of AI\"\n",
    "generated = generate_text(seed_text, model, tokenizer, num_tokens=50, temperature=1.0)\n",
    "\n",
    "print(\"📝 Generated Text:\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
